## A/B 테스트 결과 해석하기: 
---

### 개요
---
최근에 인과 추론을 공부하면서 관련된 글을 찾아보게 되었습니다. 그러다 넷플릭스 테크 블로그에서 A/B 테스트 및 통계적 지식에 대해 작성한 4개 짜리 글 시리즈의 내용이 너무 괜찮아 번역해 공유드립니다. 본문은 4개의 글 중 3번째 입니다. 첫 두 글은 introduction 및 A/B 테스트란 무엇인가에 대해 설명하는 기초적인 내용이라 건너 뛰었습니다. 본문에서는 복잡하고 머리아픈 수학적 계산이 모두 빠져있습니다. 그래서 오히려 진또배기 통계적 개념 자체에 더 집중할 수 있었다고 생각합니다.

### 본문

테스트 결과를 해석할 때 저희는 크게 두가지 실수를 할 수 있습니다. Type I: **거짓 양성(false positive)**, 그리고 Type II: **거짓 음성(false negative)** 오류입니다. 거짓 양성은 인과 추론에서 우리가 예상한대로 치료군(treatment group)에서 더 긍정적인 효과를 보였으나, 그 원인이 우리의 primary metric이 아닌 의도하지 않았던 다른 feature 때문인 것.
즉, 실제 treatment는 별 효과가 없었는데 다른 이유 때문에 효과가 있는 것 처럼 보이는 실수입니다. 거짓 음성은 그 반대로 실제로는 효과가 있었지만, 효과가 없다고 판단하는 실수입니다.

좀 더 직관적으로 알아보기 위해 '고양이 사진을 구별하는' 인공지능의 예시를 보겠습니다. 주어진 이미지에 대해 시스템은 두 가지 결정("cat" 또는 "not cat")을 내릴 수 있고, 마찬가지로 "cat" 또는 "not cat"이라는 두 가지 사실이 있습니다. 이는 아래 그림 1과 같이 총 네 개의의 가능성으로 이어집니다.  
A/B 테스트도 마찬가지입니다. 데이터를 기반으로 treatment가 유의미한 영향을 미쳤다는 근거가 충분(또는 불충분)하다는 판단을 내리고, 실제로 그 실험이 효과가 있었는지에 대한 결과도 총 두 가지입니다. that we never get to know with complete uncertainty  

"그림 1"  

거짓 양성과 거짓 음성에 대한 팩트는, 서로 반대이기 때문에 둘 다 없을 수 없다는 것입니다. 1종 오류가 적어지도록 실험 설계를 하면 2종 오류의 비율이 올라가고, 그 반대도 마찬가지입니다. 이 글에서는 몇 가지 예시를 통해 거짓 양성과 관련된 통계적 개념에 대한 얘기를 할 예정입니다. 

### 거짓 양성, 및 통계적 유의성

훌륭한 가설이 있고 1차 결정 지표에 대한 명확한 정리가 되었으면 A/B 테스트를 설계하기 위한 통계적인 측면을 고려해야합니다. 이 프로세스는 보통 허용가능한 거짓 양성 rate를 설정하는 것으로 시작합니다. 이 비율은 관례적으로 5%입니다: 치료군과 대조군의 유의미한 차이가 없더라도 5%의 확률로 우리는 통계적 유의성(statistical significance)이 있다 판단하는 실수를 할 수 있다는 의미입니다. 즉, 100번 중 5번의 꼴로 우리는 실제로 냥이가 아닌 사진을 보고 이것은 냥이 사진이라는 결론을 내리게 됩니다. 이를 우리는 "유의수준(significance level) 5%로 유의하다"라고 정의합니다. 

거짓 양성 비율은 치료군과 대조군 간의 차이(p-value를 이용해 측정하는)에서 관찰된 통계적 유의성과 밀접한 관련이 있습니다. p-value란 실제로 두 비교 집단의 차이가 없었지만, 미리 가정한 가설보다 더 극단적인 결과가 실제로 관측될 확률을 의미합니다. 간단한 확률 게임을 통해 p-value에 대해 좀 더 직관적으로 알아보겠습니다.

동전이 공평하지 않다는(앞면이 나올 확률이 50%가 아니라는)  가정을 하고 실험을 해보겠습니다. 아주 단순한 시나리오처럼 보이지만 실제로 새로운 제품경험이 사용자의 행동에 미치는 영향을 A/B 테스트를 통해 알아보려는 행위와 직접적인 관련이 있습니다. 예를들어 새로운 UI 기능을 클릭하는 것 부터 넷플릭스 서비스를 한달 더 유지하는 것과 같이 말입니다. 

위 가정을 검증하기 위해서 동전을 총 100번 던진 후 앞면이 나오는 비율을 계산합니다. 동전이 완벽하게 공평하더라도 무작위성(또는 "노이즈")으로 인해 아마 정확히 50:50이 나오지는 않을 것입니다. 그런데 50에서 ± 몇번 까지가 허용되는 범위인지 애매합니다. 앞면이 총 몇번 나와야 동전이 실제로 공평하다고 주장할 수 있을까요? 또는 그 반대로 만약 100번 중 60번이 앞면이라면 동전이 공평하지 않다고 결론을 낼만한가요? We need a way to align on a decision framework and understand the associated false positive rate.

직관적으로 알아보기 위해 한번 실험을 해보도록 하겠습니다. 먼저, 동전이 공평하다고 가정을 가정을 해봅시다 - 이것이 *현상 유지*, 또는 일반적인 사실로 받아들여지는 저희의 **귀무 가설**입니다. 이제 위 가설과 대립되는 설득력 있는 증거를 데이터로부터 찾습니다. 
설득력 있는 증거를 만들기 위해 먼저 *귀무 가설이 참이라 가정하고* 가능한 모든 결과에 대한 확률을 계산합니다. 즉, 이번 예시에서는 공평한 동전을 100번 던졌을 때 앞면이 0번 나올 확률, 1번 나올 확률, 2번 ... 100번 나올 확률을 수학적으로 계산하는 것이죠. 계산한 결과는 아래 그림 2와 같습니다(ignore the colors for now).

"그림 2"

그 다음에 위 확률 분포에 대해 저희가 실제로 수집한 데이터와 비교를 해보는 것입니다. 위 그림상 빨간 실선이 위치한 것처럼 55%의 경우에 앞면이 나왔다고 가정해봅시다. 이 관찰을 동전이 실제로 공평하지 않다는 가설의 설득력 있는 증거로 사용하기 위해, **저희 관찰보다 가능성이 낮은 모든 결과**와 관련된 확률을 계산합니다. 여기서는, 동전의 앞면이 나올 확률이 55% 이상인 경우를 전부 더하게 됩니다. 즉 빨간 실선 오른쪽에 있는 모든 경우가 나올 확률입니다.

위 값을 바로 p-value라고 합니다: 귀무 가설이 참일 때 관찰한 것보다 더 극단적인 결과가 나올 확률. 귀무 가설은 동전이 공평하다는 것, 관찰 결과는 55/100의 경우 앞면이 나왔다는 것, 그리고 p-value는 0.32 정도 입니다. 다른 말로 해석해보겠습니다: *공평한 동전 100번 던지기 실험을 여러번 반복했을 때*, 전체 실험 횟수 중 앞면 또는 뒷면(귀무 가설에 의해)이 55번 이상 나올 확률은 32% 입니다.

p-value를 이용해 코인이 공평하지 않다는 것을, 또는 새로운 고객 경험이 현재 상태보다 낫다는 것을 통계적으로 어떻게 증명할 수 있을까요? 처음에 설정해둔 유의수준 5%로 다시 돌아가서: p-value가 0.05보다 작은 경우에 통계적으로 유의한 효과가 있다는 결론을 내립니다. 즉, 실험에서 얻은 결과가 발생할 가능성이 충분히 낮으면 귀무 가설을 공식적으로 버릴 수 있는 것입니다. 공평한 동전을 100번 던져서 앞면이 55번 나오는 경우의 p-value는 0.32입니다. p-value가 0.05 유의수준보다 크기 때문에 저희는 "동전이 공평하지 않다"라는 대립 가설의 통계적으로 유의한 증거가 없다고 결론짓게 됩니다.

위와 같은 실험 또는 A/B 테스트에서 내릴 수 있는 결론은 총 두 가지입니다: "효과가 있다(동전이 공평하지 않다)" 또는 "효과가 있다는 증거가 충분하지 않다" 입니다. "Guilty" 또는 "not guilty"이라고 재판하는 배심원 시스템과 흡사하죠 - not guilty는 innocent(결백)와 아주 다릅니다. A/B 테스트에서도 이와 마찬가지로 서비스의 새 기능이 아무런 효과가 없다와 같은 결론은 내릴 수 없습니다. 단지 현재 상태인 귀무 가설을 기각할 만큼 충분한 증거가 없다고 결론지을 뿐입니다. 위의 동전 예시에서 저희는 100번 던졌을 때 앞면이 55%인 것을 관찰했고, 동전이 공평하지 않다고 갖다 붙일 정도의 근거가 충분하지 않다라고 결론지었습니다. 동전이 공평하다고 결론지은 것이 아닙니다. 만약 1000번 던졌다면 동전이 공평하다는 귀무 가설을 기각할만한 증거가 나왔을 수도 있기 때문입니다.

### Rejection Regions and Confidence Intervals
A/B 테스트에서 p-value와 밀접하게 연관되어있는 두 가지 추가적인 개념이 있습니다: **기각역**(rejection region)과 **신뢰 구간**(confidence interval) 입니다. 

기각역은 이름과 같이 귀무 가설을 기각시킬 수 있는 값의 집합입니다. 기각역을 계산하기 위해서 먼저 귀무 가설(동전은 공평하다는)을 참이라고 가정하고 기각 영역을 "발생 확률의 합이 0.05 보다 적은, 가능성이 가장 낮은 결과의 집합"이라 정의합니다. 즉, 기각역은 가설이 맞다는 가정 하에 가장 극단적인, 가설에 반대되는 증거가 가장 강력한 결과의 구성입니다. 그래서 실험의 결과가 이 영역에 속하면 귀무 가설을 기각할 만큼의 통계적으로 유의미한 증거가 있다는 결과를 내리게 됩니다. 동전 실험에서 기각역은 앞면 또는 뒷면이 나올 확률이 60% 이상인 경우(그림 2의 파란 부분)입니다. 그리고 이 경계를 **임계값**(critical value)이라고 부릅니다.

There is an equivalence between the rejection region and the p-value, and both lead to the same decision: the p-value is less than 0.05 if and only if the observation lies in the rejection region.

현재까지의 접근 방식은 귀무 가설을 세우고, 가능한 결과를 정의한 후 관찰 결과를 비교하는 순서였습니다. 하지만 신뢰구간을 이해하기 위해선 반대로 관찰 결과에 집중하는 것이 좋습니다. 그 다음 "거짓 양성 허용 비율이 5%일 때, 어떤 값이 관찰되어야 귀무 가설이 기가되지 않을까?" 한번 생각해보는 것입니다. 동전 던지기에서 앞면의 비율이 55% 일 때, 귀무 가설을 기각하지 않았습니다. 그리고 60% 일 때도 그럴 것입니다. 그림 3이 보여주듯 45% 에서 65% 정도 까지는 귀무 가설이 기각되지 않는 범위입니다.

"그림 3"

이 범위를 "신뢰 구간"이라고 합니다. 5% 유의 수준 테스트에서 구간을 매핑했기 때문에, 우리는 이를 신뢰 수준 95% 라고 부릅니다. 해석하자면, 실험을 여러번 반복하였을 때, 95%의 경우 신뢰 구간 내에 실제 값(동전 앞면이 나올 실제 확률)이 포함됩니다.

There is an equivalence between the confidence interval and the p-value, and both lead to the same decision: the 95% confidence interval does not cover the null value if and only if the p-value is less than 0.05, and in both cases we reject the null hypothesis of no effect.

### 마무리

동전 던지기를 이용한 몇가지 실험(!?)을 통해 거짓 양성 오류, 통계적 유의성, p-value, 기각역 및 신뢰 구간에 대한 개념을 쉽게 이해해보았습니다. 치료군과 대조군을 이용한 A/B 테스트에 똑같이 적용되는 핵심적인 개념입니다. 여기서의 귀무 가설은: "경험 B는 구성원 만족도에 영향을 미치지 않는다" 입니다. 
그 다음 위에서 했던 것과 똑같이 해보는 것입니다: 구성원 만족도에 차이가 없다는 가정 하에 "A"그룹 및 "B"그룹의 일차 결정 지표 값의 차이에 대해 가능한 결과값 및 해당 값과 관련된 확률이 무엇일까? 그 이후 관찰 결과를 이 분포와 비교해 p-value를 얻고 결론을 내릴 수 있습니다. 

And just like with the coin example, we can define rejection regions and calculate confidence intervals.